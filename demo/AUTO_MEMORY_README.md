# 自动记忆提取功能使用说明

## 功能概述

本次修改为 `chat_with_memory.py` 演示程序添加了**自动记忆提取和存储**功能。现在每次对话后，系统会自动将对话内容存储到记忆系统中，下次启动聊天时这些记忆可以被自动调用。

## 主要修改

### 1. 修改文件
- `demo/chat/session.py` - ChatSession类

### 2. 新增功能

#### 2.1 自动存储对话消息
在 `ChatSession.chat()` 方法中，每次对话完成后会自动：
- 存储用户输入消息
- 存储助手回复消息

这些消息会通过 `/api/v1/memories` 接口自动发送到记忆系统。

#### 2.2 对话元数据初始化
在首次存储消息前，系统会自动调用 `/api/v1/memories/conversation-meta` 接口保存对话元数据，包括：
- 场景类型（assistant/group_chat等）
- 会话ID和名称
- 参与者信息
- 时区设置

#### 2.3 记忆检索增强
启动聊天时，系统会：
- 自动加载该群组的历史记忆数量
- 在对话时根据用户输入检索相关记忆
- 将检索到的记忆作为上下文提供给LLM

## 使用方法

### 第一步：启动API服务器
```bash
uv run python src/run.py
```

### 第二步：在另一个终端启动聊天程序
```bash
uv run python src/bootstrap.py demo/chat_with_memory.py
```

或者：
```bash
cd demo
python chat_with_memory.py
```

### 第三步：正常对话
1. 选择语言
2. 选择场景（助手模式或群聊模式）
3. 选择群组
4. 选择检索模式
5. 开始对话

**重要提示**：
- 每次发送消息后，系统会自动在后台存储消息到记忆系统
- 存储过程不会中断对话流程（采用非阻塞方式）
- 即使存储失败，对话仍会继续进行

### 第四步：验证记忆功能
1. 进行几轮对话，讨论一些具体的话题
2. 输入 `exit` 退出对话
3. 重新启动聊天程序
4. 在启动时会显示已有的记忆数量
5. 询问之前讨论过的话题，系统会检索并使用之前的记忆

## 技术细节

### 消息格式
每条消息包含以下字段：
```json
{
  "message_id": "msg_<counter>_<timestamp>",
  "create_time": "2025-12-25T10:30:00+08:00",
  "sender": "User",
  "sender_name": "User",
  "type": "text",
  "content": "消息内容",
  "group_id": "group_id",
  "group_name": "Chat Session group_id",
  "scene": "assistant"
}
```

### 记忆提取时机
记忆系统采用智能提取策略：
- ✅ **会提取**：包含具体信息、观点、偏好、事件的对话
- ❌ **不会提取**：过于简短、信息量低的闲聊
- 🎯 **最佳实践**：多轮对话、丰富的上下文、具体的细节

### API接口
使用的API接口：
- `POST /api/v1/memories/conversation-meta` - 保存对话元数据
- `POST /api/v1/memories` - 存储单条消息
- `GET /api/v1/memories/search` - 检索相关记忆

## 示例场景

### 场景1：个人偏好记录
```
用户: 我喜欢周末去踢足球
助手: 运动是个好习惯！你最喜欢哪个足球队？
用户: 我最喜欢巴塞罗那，梅西是我的偶像
助手: 梅西确实是足球史上的传奇球员！

[系统自动存储这些对话]

下次启动后...
用户: 推荐一些运动相关的活动
助手: [会检索到之前关于足球的记忆，提供个性化建议]
```

### 场景2：工作任务跟踪
```
用户: 我这周需要完成项目报告
助手: 好的，什么类型的报告？
用户: 是关于AI产品的市场分析报告，需要在周五前完成
助手: 了解了，需要我帮你规划一下时间吗？

[系统自动存储]

下次启动后...
用户: 我的任务进展如何？
助手: [会检索到之前的任务信息，提供跟进]
```

## 注意事项

1. **API服务必须运行**：聊天程序依赖API服务器，请确保先启动 `src/run.py`

2. **记忆提取需要时间**：存储的消息需要经过系统的记忆提取流程才能生成结构化记忆，这个过程可能需要几秒到几分钟

3. **存储是异步的**：为了不影响对话流畅性，消息存储采用异步方式，即使存储失败对话也会继续

4. **检索模式选择**：
   - `keyword`: 关键词检索（BM25）- 速度快
   - `vector`: 向量检索 - 语义理解好
   - `hybrid`: 混合检索（关键词+向量+重排）- 效果好但较慢
   - `rrf`: RRF融合（推荐）- 平衡速度和效果
   - `agentic`: LLM引导检索 - 效果最好但最慢且消耗token

5. **时区设置**：默认使用 `Asia/Shanghai` 时区，可以根据需要修改

## 故障排查

### 问题1：无法连接API服务器
**错误信息**：`Cannot connect to API server: http://localhost:1995`

**解决方法**：
```bash
# 在另一个终端启动API服务器
uv run python src/run.py
```

### 问题2：记忆检索不到之前的对话
**可能原因**：
1. 记忆提取还在进行中（等待几分钟后重试）
2. 对话内容过于简短，系统判断为不需要提取的闲聊
3. 使用了不同的 group_id

**解决方法**：
1. 等待一段时间让系统完成记忆提取
2. 进行更多轮、更具体的对话
3. 使用相同的 group_id 启动聊天

### 问题3：记忆数量为0
**可能原因**：首次使用或数据库中没有该group的记忆

**解决方法**：
1. 进行几轮有意义的对话
2. 等待记忆提取完成
3. 重新启动聊天程序查看记忆数量

## 总结

通过这次修改，chat_with_memory.py 演示程序实现了真正的"记忆功能"：
- ✅ 对话会自动保存到记忆系统
- ✅ 下次启动时会加载历史记忆
- ✅ 对话时会自动检索相关记忆
- ✅ 记忆会作为上下文提供给LLM
- ✅ 实现了持久化的对话记忆能力

这使得聊天助手能够真正"记住"用户的信息，提供更加个性化和连贯的对话体验！
